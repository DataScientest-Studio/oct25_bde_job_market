{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c8ad5b0-668c-48db-a839-61662b104c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04137018-7f5b-4ab2-9a72-f461a4103af2",
   "metadata": {},
   "source": [
    "First we load the data by connecting to Postgres and Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a9564f-8333-45e1-8e62-4dfccbe63d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to postgres db\n",
    "#engine = create_engine(os.getenv(\"PG_CONN\"))\n",
    "#df = pd.read_sql(\"SELECT * FROM jobs\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09f718-09ca-4190-a32d-1a82ca68a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs = pd.read_sql(\"SELECT * FROM job\", engine)\n",
    "#com = pd.read_sql(\"SELECT * FROM company\", engine)\n",
    "#cat = pd.read_sql(\"SELECT * FROM category\", engine)\n",
    "#locs = pd.read_sql(\"SELECT * FROM location\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6562cc3f-edcb-48dc-8735-d4d1eed31688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'local']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(client.list_database_names())\n",
    "\n",
    "# List all collections in your database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9cf3199-682d-4f2a-b3cd-51c4990a4959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##connect to mongodb\n",
    "load_dotenv()\n",
    "client = MongoClient(\n",
    "    'mongodb://{}:{}@localhost:27017/jobmarketdb?authSource=admin'.format(\n",
    "        os.getenv('MONGO_USER'),\n",
    "        os.getenv('MONGO_PASS')\n",
    "    )\n",
    ")\n",
    "db = client['jobmarketdb']\n",
    "collection = db['adzunajobs']\n",
    "\n",
    "cursor = collection.find(\n",
    "    {},                             # all documents\n",
    "    {\"_id\": 0, \"job_id\": 1, \"job_description\": 1}   # only these fields\n",
    ")\n",
    "\n",
    "#df_mongo = pd.DataFrame(list(cursor))\n",
    "#df_mongo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8a58f82-2796-48aa-a354-4a1c60408251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_description</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5494605665</td>\n",
       "      <td>Du weißt, was Du kannst – und suchst einen Arb...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5471852220</td>\n",
       "      <td>DIREKTVERMITTLUNG in Festanstellung (keine Ze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5491386603</td>\n",
       "      <td>Bereit für den nächsten Karriereschritt? Wir b...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5484898587</td>\n",
       "      <td>Du willst Dein Fachwissen in einem neuen Arbei...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5492488590</td>\n",
       "      <td>Unternehmen Ein international tätiges, produzi...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>95000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                                    job_description  salary_min  \\\n",
       "0  5494605665  Du weißt, was Du kannst – und suchst einen Arb...        18.0   \n",
       "1  5471852220   DIREKTVERMITTLUNG in Festanstellung (keine Ze...         NaN   \n",
       "2  5491386603  Bereit für den nächsten Karriereschritt? Wir b...        16.0   \n",
       "3  5484898587  Du willst Dein Fachwissen in einem neuen Arbei...     70000.0   \n",
       "4  5492488590  Unternehmen Ein international tätiges, produzi...     75000.0   \n",
       "\n",
       "   salary_max  \n",
       "0        20.0  \n",
       "1         NaN  \n",
       "2        18.0  \n",
       "3     80000.0  \n",
       "4     95000.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mongo = pd.read_json('adzunajobs.json')\n",
    "df_mongo = df_mongo[['id', 'description', 'salary_min', 'salary_max']]\n",
    "df_mongo = df_mongo.rename(columns={\"id\": \"job_id\", \"description\": \"job_description\"})\n",
    "df_mongo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9ae2013-f2e9-4702-b362-47a8043b97b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>contract_time</th>\n",
       "      <th>created</th>\n",
       "      <th>adref</th>\n",
       "      <th>redirect_url</th>\n",
       "      <th>salary_is_predicted</th>\n",
       "      <th>company_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>job_description</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5494004615</td>\n",
       "      <td>Senior Software Engineer FIND - Solr (Remote -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-13 15:51:45</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5NDAwNDYxNSIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5494004615?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This position is posted by Jobgether on behalf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5489819814</td>\n",
       "      <td>(Senior) Softwareentwickler Java / Java EE (m/...</td>\n",
       "      <td>permanent</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-10 21:16:57</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4OTgxOTgxNCIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5489819814?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Almoshof, Nürnberg</td>\n",
       "      <td>49.49109</td>\n",
       "      <td>11.06150</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Nürnberg</td>\n",
       "      <td>DIREKTVERMITTLUNG in Festanstellung (keine Ze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5474059769</td>\n",
       "      <td>Gabelstaplerfahrer (m/w/d)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-01 06:05:51</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...</td>\n",
       "      <td>https://www.adzuna.de/details/5474059769?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Odelzhausen, Dachau (Kreis)</td>\n",
       "      <td>48.30932</td>\n",
       "      <td>11.19440</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Dachau (Kreis)</td>\n",
       "      <td>Wir suchen Dich! Denn für unsere Kunden brauch...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5486087702</td>\n",
       "      <td>Java-Software-Architekt (m/w/d)</td>\n",
       "      <td>permanent</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-07 21:18:24</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4NjA4NzcwMiIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5486087702?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte, Berlin</td>\n",
       "      <td>52.52219</td>\n",
       "      <td>13.40933</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>DIREKTVERMITTLUNG in Festanstellung (keine Ze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5486087702</td>\n",
       "      <td>Java-Software-Architekt (m/w/d)</td>\n",
       "      <td>permanent</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-07 21:18:24</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4NjA4NzcwMiIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5486087702?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte, Berlin</td>\n",
       "      <td>52.52219</td>\n",
       "      <td>13.40933</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>DIREKTVERMITTLUNG in Festanstellung (keine Ze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                                              title  \\\n",
       "0  5494004615  Senior Software Engineer FIND - Solr (Remote -...   \n",
       "1  5489819814  (Senior) Softwareentwickler Java / Java EE (m/...   \n",
       "2  5474059769                         Gabelstaplerfahrer (m/w/d)   \n",
       "3  5486087702                    Java-Software-Architekt (m/w/d)   \n",
       "4  5486087702                    Java-Software-Architekt (m/w/d)   \n",
       "\n",
       "  contract_type contract_time              created  \\\n",
       "0           NaN     full_time  2025-11-13 15:51:45   \n",
       "1     permanent     full_time  2025-11-10 21:16:57   \n",
       "2           NaN     full_time  2025-11-01 06:05:51   \n",
       "3     permanent     full_time  2025-11-07 21:18:24   \n",
       "4     permanent     full_time  2025-11-07 21:18:24   \n",
       "\n",
       "                                               adref  \\\n",
       "0  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5NDAwNDYxNSIsI...   \n",
       "1  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4OTgxOTgxNCIsI...   \n",
       "2  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...   \n",
       "3  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4NjA4NzcwMiIsI...   \n",
       "4  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4NjA4NzcwMiIsI...   \n",
       "\n",
       "                                        redirect_url  salary_is_predicted  \\\n",
       "0  https://www.adzuna.de/details/5494004615?utm_m...                    0   \n",
       "1  https://www.adzuna.de/details/5489819814?utm_m...                    0   \n",
       "2  https://www.adzuna.de/details/5474059769?utm_m...                    0   \n",
       "3  https://www.adzuna.de/details/5486087702?utm_m...                    0   \n",
       "4  https://www.adzuna.de/details/5486087702?utm_m...                    0   \n",
       "\n",
       "   company_id  location_id  category_id                 display_name  \\\n",
       "0           2            2            1                  Deutschland   \n",
       "1           3            3            1           Almoshof, Nürnberg   \n",
       "2          12           12            1  Odelzhausen, Dachau (Kreis)   \n",
       "3           3           21            1                Mitte, Berlin   \n",
       "4           3           21            1                Mitte, Berlin   \n",
       "\n",
       "   latitude  longitude      country            city  \\\n",
       "0       NaN        NaN  Deutschland             NaN   \n",
       "1  49.49109   11.06150  Deutschland        Nürnberg   \n",
       "2  48.30932   11.19440  Deutschland  Dachau (Kreis)   \n",
       "3  52.52219   13.40933  Deutschland          Berlin   \n",
       "4  52.52219   13.40933  Deutschland          Berlin   \n",
       "\n",
       "                                     job_description  salary_min  salary_max  \n",
       "0  This position is posted by Jobgether on behalf...         NaN         NaN  \n",
       "1   DIREKTVERMITTLUNG in Festanstellung (keine Ze...         NaN         NaN  \n",
       "2  Wir suchen Dich! Denn für unsere Kunden brauch...        18.0        20.0  \n",
       "3   DIREKTVERMITTLUNG in Festanstellung (keine Ze...         NaN         NaN  \n",
       "4   DIREKTVERMITTLUNG in Festanstellung (keine Ze...         NaN         NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##combine data into one df\n",
    "df = jobs.join(locs, how = 'left', on = 'location_id')\n",
    "df = df.merge(df_mongo)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47e9793d-3e31-411c-9aff-7b49506f11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs = pd.read_csv(\"job.csv\")\n",
    "#jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0c37f94-a09a-4a51-a657-8a930b7481ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "job_id                   int64\n",
      "title                   object\n",
      "contract_type           object\n",
      "contract_time           object\n",
      "created                 object\n",
      "adref                   object\n",
      "redirect_url            object\n",
      "salary_is_predicted      int64\n",
      "company_id               int64\n",
      "location_id              int64\n",
      "category_id              int64\n",
      "display_name            object\n",
      "latitude               float64\n",
      "longitude              float64\n",
      "country                 object\n",
      "city                    object\n",
      "job_description         object\n",
      "salary_min             float64\n",
      "salary_max             float64\n",
      "dtype: object\n",
      "\n",
      "==================================================\n",
      "\n",
      "Missing Values:\n",
      "               Missing_Count  Percentage\n",
      "salary_max                 9   69.230769\n",
      "salary_min                 9   69.230769\n",
      "contract_type              5   38.461538\n",
      "city                       2   15.384615\n",
      "latitude                   2   15.384615\n",
      "longitude                  2   15.384615\n",
      "contract_time              1    7.692308\n",
      "\n",
      "==================================================\n",
      "\n",
      "Basic Statistics:\n",
      "             job_id  salary_is_predicted  company_id  location_id  \\\n",
      "count  1.300000e+01                 13.0   13.000000    13.000000   \n",
      "mean   5.476565e+09                  0.0   13.769231    24.384615   \n",
      "std    1.915704e+07                  0.0   16.931991    15.877334   \n",
      "min    5.440550e+09                  0.0    1.000000     2.000000   \n",
      "25%    5.474060e+09                  0.0    3.000000    12.000000   \n",
      "50%    5.484338e+09                  0.0    3.000000    28.000000   \n",
      "75%    5.489820e+09                  0.0   28.000000    38.000000   \n",
      "max    5.494005e+09                  0.0   49.000000    49.000000   \n",
      "\n",
      "       category_id   latitude  longitude   salary_min    salary_max  \n",
      "count         13.0  11.000000  11.000000      4.00000      4.000000  \n",
      "mean           1.0  50.331485  11.134476  15015.50000  17517.000000  \n",
      "std            0.0   1.925562   1.798673  29989.66677  34988.666756  \n",
      "min            1.0  47.927510   8.235274     18.00000     20.000000  \n",
      "25%            1.0  48.531993   9.924840     19.50000     21.500000  \n",
      "50%            1.0  49.802740  11.194400     22.00000     24.000000  \n",
      "75%            1.0  52.313500  12.515585  15018.00000  17519.500000  \n",
      "max            1.0  52.522190  13.409330  60000.00000  70000.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing_Count'] > 0].sort_values('Percentage', ascending=False))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14d675-1be4-4495-bb76-b3b7550eccff",
   "metadata": {},
   "source": [
    "**Data Prep and Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "184a4a53-b30f-4b8b-84bc-c498b93dbd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "\n",
      "Rows after cleaning: 4 (removed 9 rows)\n",
      "Missing values remaining:\n",
      "contract_type    4\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5176/1385761668.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean['city'].fillna('Unknown', inplace=True)\n",
      "/tmp/ipykernel_5176/1385761668.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean['country'].fillna('Deutschland', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Handle missing values in numeric columns (latitude, longitude)\n",
    "print(\"Handling missing values...\")\n",
    "\n",
    "# df_clean = df_clean.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# 2. Handle missing values in categorical columns (city, country)\n",
    "# Fill with 'Unknown' or mode\n",
    "df_clean['city'].fillna('Unknown', inplace=True)\n",
    "df_clean['country'].fillna('Deutschland', inplace=True)  \n",
    "\n",
    "# 3. Handle salary columns - remove rows where salary is missing or invalid\n",
    "df_clean = df_clean.dropna(subset=['salary_min', 'salary_max'])\n",
    "\n",
    "# Remove rows where salary_max < salary_min (data quality issue)\n",
    "df_clean = df_clean[df_clean['salary_max'] >= df_clean['salary_min']]\n",
    "\n",
    "# Remove extreme outliers in salary\n",
    "def remove_outliers(df, column, n_std=3):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    return df[abs(df[column] - mean) <= n_std * std]\n",
    "\n",
    "df_clean = remove_outliers(df_clean, 'salary_max', n_std=3)\n",
    "\n",
    "print(f\"\\nRows after cleaning: {len(df_clean)} (removed {len(df) - len(df_clean)} rows)\")\n",
    "print(f\"Missing values remaining:\\n{df_clean.isnull().sum()[df_clean.isnull().sum() > 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15149855-7904-42fc-8358-f763d63d0ec2",
   "metadata": {},
   "source": [
    "**Keyword extraction from job description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe4e66-1ca9-41ec-bf4e-86dc4e0c2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing descriptions\n",
    "df_clean['job_description'] = df_clean['job_description'].fillna('')\n",
    "\n",
    "# Convert to lowercase for consistency\n",
    "df_clean['desc_lower'] = df_clean['job_description'].str.lower()\n",
    "\n",
    "# Define comprehensive keyword categories\n",
    "keywords_dict = {\n",
    "    # Seniority levels\n",
    "    'seniority': ['senior', 'lead', 'principal', 'staff', 'junior', 'entry', \n",
    "                  'experienced', 'expert', 'chief', 'head of', 'director', 'vp'],\n",
    "    \n",
    "    # Technical skills - Programming languages\n",
    "    'languages': ['python', 'java', 'javascript', 'typescript', 'c++', 'c#', \n",
    "                  'ruby', 'go', 'rust', 'scala', 'kotlin', 'swift', 'php', 'r'],\n",
    "    \n",
    "    # Frameworks & Technologies\n",
    "    'frameworks': ['react', 'angular', 'vue', 'django', 'flask', 'spring', \n",
    "                   'node.js', 'express', '.net', 'tensorflow', 'pytorch', 'keras'],\n",
    "    \n",
    "    # Databases\n",
    "    'databases': ['sql', 'mysql', 'postgresql', 'mongodb', 'oracle', 'redis', \n",
    "                  'elasticsearch', 'cassandra', 'dynamodb', 'neo4j'],\n",
    "    \n",
    "    # Cloud & DevOps\n",
    "    'cloud': ['aws', 'azure', 'gcp', 'cloud', 'docker', 'kubernetes', 'k8s',\n",
    "              'terraform', 'ansible', 'jenkins', 'gitlab', 'ci/cd', 'devops'],\n",
    "    \n",
    "    # Data & AI\n",
    "    'data_ai': ['machine learning', 'deep learning', 'ai', 'data science', \n",
    "                'analytics', 'big data', 'etl', 'data warehouse', 'spark', \n",
    "                'hadoop', 'tableau', 'power bi'],\n",
    "    \n",
    "    # Methodologies\n",
    "    'methodologies': ['agile', 'scrum', 'kanban', 'waterfall', 'test-driven',\n",
    "                      'microservices', 'rest', 'api', 'graphql'],\n",
    "    \n",
    "    # Soft skills & Management\n",
    "    'management': ['team lead', 'leadership', 'management', 'communication',\n",
    "                   'project management', 'stakeholder', 'mentor', 'architect'],\n",
    "    \n",
    "    # Education requirements\n",
    "    'education': ['bachelor', 'master', 'phd', 'doctorate', 'degree', \n",
    "                  'university', 'certification', 'certified'],\n",
    "    \n",
    "    # Experience indicators\n",
    "    'experience': ['years of experience', 'year experience', 'experience in',\n",
    "                   'proven track record', 'extensive experience'],\n",
    "    \n",
    "    # Domain expertise\n",
    "    'domains': ['finance', 'fintech', 'healthcare', 'e-commerce', 'automotive',\n",
    "                'telecommunications', 'gaming', 'security', 'blockchain', 'iot'],\n",
    "    \n",
    "    # Company size indicators\n",
    "    'company_type': ['startup', 'enterprise', 'corporation', 'sme', 'scale-up',\n",
    "                     'fortune 500', 'multinational'],\n",
    "    \n",
    "    # Benefits (often correlate with higher salaries)\n",
    "    'benefits': ['remote', 'flexible', 'home office', 'relocation', 'visa',\n",
    "                 'bonus', 'stock options', 'equity', '30 days vacation']\n",
    "}\n",
    "\n",
    "# Count keyword occurrences in each category\n",
    "for category, keywords in keywords_dict.items():\n",
    "    df_clean[f'{category}_count'] = 0\n",
    "    for keyword in keywords:\n",
    "        df_clean[f'{category}_count'] += df_clean['desc_lower'].str.contains(\n",
    "            keyword, regex=False, na=False\n",
    "        ).astype(int)\n",
    "    print(f\"{category}: mean count = {df_clean[f'{category}_count'].mean():.2f}\")\n",
    "\n",
    "# Create binary features for high-impact individual keywords\n",
    "high_impact_keywords = [\n",
    "    'senior', 'lead', 'principal', 'architect', 'expert',\n",
    "    'python', 'java', 'aws', 'azure', 'kubernetes',\n",
    "    'machine learning', 'ai', 'blockchain', \n",
    "    'remote', 'phd', 'team lead'\n",
    "]\n",
    "\n",
    "for keyword in high_impact_keywords:\n",
    "    col_name = f\"has_{keyword.replace(' ', '_')}\"\n",
    "    df_clean[col_name] = df_clean['desc_lower'].str.contains(\n",
    "        keyword, regex=False, na=False\n",
    "    ).astype(int)\n",
    "\n",
    "print(f\"\\nCreated {len(keywords_dict)} category count features\")\n",
    "print(f\"Created {len(high_impact_keywords)} binary keyword features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41dbd3-cb81-4282-8a84-69a7713ee734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional text-based features\n",
    "df_clean['desc_length'] = df_clean['job_description'].str.len()\n",
    "df_clean['desc_word_count'] = df_clean['job_description'].str.split().str.len()\n",
    "df_clean['desc_sentence_count'] = df_clean['job_description'].str.count(r'[.!?]+')\n",
    "\n",
    "# Extract years of experience mentioned (e.g., \"5+ years\", \"3-5 years\")\n",
    "import re\n",
    "\n",
    "def extract_years_experience(text):\n",
    "    if pd.isna(text) or text == '':\n",
    "        return 0\n",
    "    # Look for patterns like \"5+ years\", \"3-5 years\", \"5 years\"\n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s*(?:years?|jahr)',  # 5+ years, 5 years\n",
    "        r'(\\d+)\\s*(?:-|to|bis)\\s*\\d+\\s*(?:years?|jahr)',  # 3-5 years\n",
    "    ]\n",
    "    years = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text.lower())\n",
    "        years.extend([int(m) for m in matches if m])\n",
    "    return max(years) if years else 0\n",
    "\n",
    "df_clean['years_experience_required'] = df_clean['job_description'].apply(extract_years_experience)\n",
    "\n",
    "# Count technical requirements\n",
    "df_clean['requirements_count'] = df_clean['desc_lower'].str.count(\n",
    "    r'\\b(require|must|need|essential|mandatory)\\b'\n",
    ")\n",
    "\n",
    "# Count \"nice to have\" vs \"must have\"\n",
    "df_clean['nice_to_have_count'] = df_clean['desc_lower'].str.count(\n",
    "    r'\\b(nice to have|preferred|bonus|plus|advantage)\\b'\n",
    ")\n",
    "\n",
    "print(\"Advanced text features:\")\n",
    "print(df_clean[['desc_length', 'desc_word_count', 'years_experience_required', \n",
    "                'requirements_count', 'nice_to_have_count']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c72a4275-2592-45d9-b52f-17311b96ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top TF-IDF terms:\n",
      "['00' '00 je' 'als' 'arbeitssicherheit' 'arbeitssicherheit in'\n",
      " 'arbeitsvertrag' 'bei' 'bei diesem' 'bei persona' 'dein' 'der' 'die'\n",
      " 'du dich' 'erwarten' 'fachkraft arbeitssicherheit' 'fachwissen'\n",
      " 'freuen kannst' 'für' 'gehalt' 'gutes']\n",
      "\n",
      "Added 50 TF-IDF features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TF-IDF features from job descriptions\n",
    "# Use a limited number of features to avoid overfitting\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50,  # Top 50 most important terms\n",
    "    min_df=5,  # Term must appear in at least 5 documents\n",
    "    max_df=0.8,  # Ignore terms that appear in more than 80% of documents\n",
    "    ngram_range=(1, 2),  # Use single words and bi-grams\n",
    "    stop_words=['german']  # Remove common German words\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "tfidf_features = tfidf.fit_transform(df_clean['job_description'].fillna(''))\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_features.toarray(),\n",
    "    columns=[f'tfidf_{i}' for i in range(tfidf_features.shape[1])],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "# Show most important terms\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(\"Top TF-IDF terms:\")\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Merge TF-IDF features with main dataframe\n",
    "df_clean = pd.concat([df_clean, tfidf_df], axis=1)\n",
    "\n",
    "print(f\"\\nAdded {tfidf_features.shape[1]} TF-IDF features\")\n",
    "\n",
    "# Optional: Show which terms are most correlated with salary\n",
    "if 'salary_avg' in df_clean.columns:\n",
    "    correlations = []\n",
    "    for col in tfidf_df.columns:\n",
    "        corr = df_clean[col].corr(df_clean['salary_avg'])\n",
    "        if not pd.isna(corr):\n",
    "            correlations.append((col, corr, feature_names[int(col.split('_')[1])]))\n",
    "    \n",
    "    correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    print(\"\\nTop 10 salary-correlated terms:\")\n",
    "    for col, corr, term in correlations[:10]:\n",
    "        print(f\"  {term}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a9cd1-25d7-407b-b6ea-8f098fe7726e",
   "metadata": {},
   "source": [
    "**Feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec9142b6-bf63-4698-b82a-96ec43849e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete!\n",
      "Total features: 79\n",
      "\n",
      "Top 15 text features correlated with salary:\n",
      "tfidf_3     1.000000\n",
      "tfidf_14    1.000000\n",
      "tfidf_4     1.000000\n",
      "tfidf_29    1.000000\n",
      "tfidf_37    1.000000\n",
      "tfidf_22    1.000000\n",
      "tfidf_44    1.000000\n",
      "tfidf_9     0.864738\n",
      "tfidf_2     0.730579\n",
      "tfidf_23    0.548340\n",
      "tfidf_15    0.337213\n",
      "tfidf_21    0.337213\n",
      "tfidf_47    0.337213\n",
      "tfidf_12    0.185453\n",
      "tfidf_31   -0.333347\n",
      "Name: salary_avg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create target variable: average salary\n",
    "df_clean['salary_avg'] = (df_clean['salary_min'] + df_clean['salary_max']) / 2\n",
    "df_clean['salary_range'] = df_clean['salary_max'] - df_clean['salary_min']\n",
    "\n",
    "# Create binary features from categorical variables\n",
    "df_clean['has_location'] = df_clean['city'].notna().astype(int)\n",
    "\n",
    "# Extract useful features from display_name (job title)\n",
    "df_clean['title_length'] = df_clean['display_name'].str.len()\n",
    "df_clean['title_word_count'] = df_clean['display_name'].str.split().str.len()\n",
    "\n",
    "# Check for keywords in job titles\n",
    "title_keywords = ['senior', 'lead', 'manager', 'engineer', 'developer']\n",
    "for keyword in title_keywords:\n",
    "    df_clean[f'title_is_{keyword}'] = df_clean['display_name'].str.lower().str.contains(\n",
    "        keyword, na=False\n",
    "    ).astype(int)\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(f\"Total features: {len(df_clean.columns)}\")\n",
    "\n",
    "# Show correlation of text features with salary\n",
    "text_feature_cols = [col for col in df_clean.columns if any(\n",
    "    x in col for x in ['_count', 'has_', 'desc_', 'years_experience', 'tfidf_']\n",
    ")]\n",
    "\n",
    "if 'salary_avg' in df_clean.columns and text_feature_cols:\n",
    "    correlations = df_clean[text_feature_cols + ['salary_avg']].corr()['salary_avg'].sort_values(ascending=False)\n",
    "    print(\"\\nTop 15 text features correlated with salary:\")\n",
    "    print(correlations[1:16])  # Skip salary_avg itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a534ba3b-9cea-48da-9f40-9ea9548a960c",
   "metadata": {},
   "source": [
    "**Encode categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e37ba8e1-94f3-4cec-9833-0a7d366ede6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>adref</th>\n",
       "      <th>redirect_url</th>\n",
       "      <th>salary_is_predicted</th>\n",
       "      <th>category_id</th>\n",
       "      <th>job_age_days</th>\n",
       "      <th>title_(Senior) Softwareentwickler Java / Java EE (m/w/d) ab jetzt</th>\n",
       "      <th>title_.NET Software Engineer</th>\n",
       "      <th>title_Bauingenieur Gebäudemanagement (m/w/d)</th>\n",
       "      <th>title_CNC-Dreher (m/w/d)</th>\n",
       "      <th>...</th>\n",
       "      <th>location_id_40</th>\n",
       "      <th>location_id_41</th>\n",
       "      <th>location_id_42</th>\n",
       "      <th>location_id_44</th>\n",
       "      <th>location_id_45</th>\n",
       "      <th>location_id_46</th>\n",
       "      <th>location_id_47</th>\n",
       "      <th>location_id_48</th>\n",
       "      <th>location_id_49</th>\n",
       "      <th>location_id_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5485243050</th>\n",
       "      <td>2025-11-07 13:05:18</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...</td>\n",
       "      <td>https://www.adzuna.de/details/5485243050?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494004615</th>\n",
       "      <td>2025-11-13 15:51:45</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5NDAwNDYxNSIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5494004615?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489819814</th>\n",
       "      <td>2025-11-10 21:16:57</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4OTgxOTgxNCIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5489819814?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482662909</th>\n",
       "      <td>2025-11-05 20:35:43</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...</td>\n",
       "      <td>https://www.adzuna.de/details/5482662909?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467966903</th>\n",
       "      <td>2025-10-28 14:05:56</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...</td>\n",
       "      <td>https://www.adzuna.de/details/5467966903?utm_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created  \\\n",
       "job_id                           \n",
       "5485243050 2025-11-07 13:05:18   \n",
       "5494004615 2025-11-13 15:51:45   \n",
       "5489819814 2025-11-10 21:16:57   \n",
       "5482662909 2025-11-05 20:35:43   \n",
       "5467966903 2025-10-28 14:05:56   \n",
       "\n",
       "                                                        adref  \\\n",
       "job_id                                                          \n",
       "5485243050  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...   \n",
       "5494004615  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5NDAwNDYxNSIsI...   \n",
       "5489819814  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4OTgxOTgxNCIsI...   \n",
       "5482662909  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...   \n",
       "5467966903  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiTXFZR2pmWEU4Qkd5Q...   \n",
       "\n",
       "                                                 redirect_url  \\\n",
       "job_id                                                          \n",
       "5485243050  https://www.adzuna.de/details/5485243050?utm_m...   \n",
       "5494004615  https://www.adzuna.de/details/5494004615?utm_m...   \n",
       "5489819814  https://www.adzuna.de/details/5489819814?utm_m...   \n",
       "5482662909  https://www.adzuna.de/details/5482662909?utm_m...   \n",
       "5467966903  https://www.adzuna.de/details/5467966903?utm_m...   \n",
       "\n",
       "            salary_is_predicted  category_id  job_age_days  \\\n",
       "job_id                                                       \n",
       "5485243050                    0            1            11   \n",
       "5494004615                    0            1             5   \n",
       "5489819814                    0            1             7   \n",
       "5482662909                    0            1            12   \n",
       "5467966903                    0            1            21   \n",
       "\n",
       "            title_(Senior) Softwareentwickler Java / Java EE (m/w/d) ab jetzt  \\\n",
       "job_id                                                                          \n",
       "5485243050                                              False                   \n",
       "5494004615                                              False                   \n",
       "5489819814                                               True                   \n",
       "5482662909                                              False                   \n",
       "5467966903                                              False                   \n",
       "\n",
       "            title_.NET Software Engineer  \\\n",
       "job_id                                     \n",
       "5485243050                         False   \n",
       "5494004615                         False   \n",
       "5489819814                         False   \n",
       "5482662909                         False   \n",
       "5467966903                         False   \n",
       "\n",
       "            title_Bauingenieur Gebäudemanagement (m/w/d)  \\\n",
       "job_id                                                     \n",
       "5485243050                                         False   \n",
       "5494004615                                         False   \n",
       "5489819814                                         False   \n",
       "5482662909                                         False   \n",
       "5467966903                                         False   \n",
       "\n",
       "            title_CNC-Dreher (m/w/d)  ...  location_id_40  location_id_41  \\\n",
       "job_id                                ...                                   \n",
       "5485243050                     False  ...           False           False   \n",
       "5494004615                     False  ...           False           False   \n",
       "5489819814                     False  ...           False           False   \n",
       "5482662909                     False  ...           False           False   \n",
       "5467966903                     False  ...           False           False   \n",
       "\n",
       "            location_id_42  location_id_44  location_id_45  location_id_46  \\\n",
       "job_id                                                                       \n",
       "5485243050           False           False           False           False   \n",
       "5494004615           False           False           False           False   \n",
       "5489819814           False           False           False           False   \n",
       "5482662909           False           False           False           False   \n",
       "5467966903           False           False           False           False   \n",
       "\n",
       "            location_id_47  location_id_48  location_id_49  location_id_50  \n",
       "job_id                                                                      \n",
       "5485243050           False           False           False           False  \n",
       "5494004615           False           False           False           False  \n",
       "5489819814           False           False           False           False  \n",
       "5482662909           False           False           False           False  \n",
       "5467966903           False           False           False           False  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for modeling\n",
    "categorical_cols = ['country', 'city']\n",
    "\n",
    "# Get all text-based features we created\n",
    "text_feature_cols = [col for col in df_clean.columns if any(\n",
    "    x in col for x in ['_count', 'has_', 'desc_length', 'desc_word_count', \n",
    "                       'years_experience', 'requirements_count', 'nice_to_have_count',\n",
    "                       'title_is_', 'tfidf_']\n",
    ")]\n",
    "\n",
    "numeric_cols = ['latitude', 'longitude', 'title_length', 'title_word_count'] + text_feature_cols\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_clean[f'{col}_encoded'] = le.fit_transform(df_clean[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Frequency encoding for city (better for high cardinality)\n",
    "city_freq = df_clean['city'].value_counts(normalize=True)\n",
    "df_clean['city_frequency'] = df_clean['city'].map(city_freq)\n",
    "\n",
    "print(f\"Total numeric/text features: {len(text_feature_cols)}\")\n",
    "print(\"Encoded features complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eabbc5-4c35-4327-bc2c-ef06d1cb6c99",
   "metadata": {},
   "source": [
    "**Prepare for data modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a87dc24d-0045-43c2-9586-5f7be70e3486",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Int64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDTypePromotionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m)\n\u001b[32m      5\u001b[39m model = LinearRegression()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:618\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    614\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    616\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:929\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    925\u001b[39m pandas_requires_conversion = \u001b[38;5;28many\u001b[39m(\n\u001b[32m    926\u001b[39m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[32m    927\u001b[39m )\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np.dtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     dtype_orig = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[32m    931\u001b[39m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[32m    932\u001b[39m     dtype_orig = \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[31mDTypePromotionError\u001b[39m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Int64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.BoolDType'>)"
     ]
    }
   ],
   "source": [
    "# Define feature columns\n",
    "feature_cols = (numeric_cols + \n",
    "                [f'{col}_encoded' for col in categorical_cols if col in df_clean.columns] + \n",
    "                ['city_frequency'])\n",
    "\n",
    "# Remove any features that might leak information or cause issues\n",
    "feature_cols = [col for col in feature_cols if col in df_clean.columns \n",
    "                and col not in ['salary_range', 'salary_avg', 'salary_min', 'salary_max']]\n",
    "\n",
    "# Remove any columns with all NaN or constant values\n",
    "valid_features = []\n",
    "for col in feature_cols:\n",
    "    if df_clean[col].notna().sum() > 0 and df_clean[col].nunique() > 1:\n",
    "        valid_features.append(col)\n",
    "    else:\n",
    "        print(f\"Removing {col}: insufficient variation\")\n",
    "\n",
    "feature_cols = valid_features\n",
    "\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean['salary_avg']\n",
    "\n",
    "# Handle any remaining NaN values in features\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")\n",
    "print(f\"Text-based features: {len([c for c in feature_cols if any(x in c for x in ['has_', '_count', 'tfidf_', 'years_experience'])])}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17434dfd-b950-4e74-8af2-b8243c327395",
   "metadata": {},
   "source": [
    "**Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a772e03-3db4-4ea8-a6de-b05750e2361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures scaled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec67755-a115-4674-b441-dbdc9428670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb  # Install with: pip install xgboost\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=200, \n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled data for linear models, original for tree-based\n",
    "    if 'Regression' in name and 'Forest' not in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"  MAE: €{mae:,.2f}\")\n",
    "    print(f\"  RMSE: €{rmse:,.2f}\")\n",
    "    print(f\"  R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc947da-5897-4120-bfd7-06807a615f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model (highest R2)\n",
    "best_model_name = comparison_df.loc[comparison_df['R2'].idxmax(), 'Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# Feature importance for tree-based models\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features:\")\n",
    "    print(importance_df.head(20).to_string(index=False))\n",
    "    \n",
    "    # Categorize features\n",
    "    text_features = importance_df[importance_df['Feature'].str.contains('has_|_count|tfidf_|years_experience')]\n",
    "    location_features = importance_df[importance_df['Feature'].str.contains('city|country|latitude|longitude')]\n",
    "    \n",
    "    print(f\"\\nTop text-based features:\")\n",
    "    print(text_features.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize top features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(20)\n",
    "    plt.barh(top_features['Feature'], top_features['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show keyword category importance\n",
    "    category_importance = {}\n",
    "    for category in keywords_dict.keys():\n",
    "        cat_features = importance_df[importance_df['Feature'].str.contains(category)]\n",
    "        if len(cat_features) > 0:\n",
    "            category_importance[category] = cat_features['Importance'].sum()\n",
    "    \n",
    "    if category_importance:\n",
    "        cat_imp_df = pd.DataFrame(list(category_importance.items()), \n",
    "                                   columns=['Category', 'Total_Importance']).sort_values('Total_Importance', ascending=False)\n",
    "        print(\"\\nKeyword category importance:\")\n",
    "        print(cat_imp_df.to_string(index=False))\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(cat_imp_df['Category'], cat_imp_df['Total_Importance'])\n",
    "        plt.xlabel('Total Importance')\n",
    "        plt.title('Keyword Category Importance')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# For linear models, show coefficients\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Coefficient': best_model.coef_\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features (by coefficient magnitude):\")\n",
    "    print(coef_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27a416-ab49-45fe-a30f-e8c92e1d0802",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3944ac5-b749-48d3-b3e8-b63d3445c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, best_predictions, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Salary (€)')\n",
    "axes[0].set_ylabel('Predicted Salary (€)')\n",
    "axes[0].set_title(f'Actual vs Predicted Salaries - {best_model_name}')\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test - best_predictions\n",
    "axes[1].scatter(best_predictions, residuals, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Predicted Salary (€)')\n",
    "axes[1].set_ylabel('Residuals (€)')\n",
    "axes[1].set_title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=50, edgecolor='black')\n",
    "plt.xlabel('Prediction Error (€)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Perfect Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nError Statistics:\")\n",
    "print(f\"Mean Error: €{residuals.mean():,.2f}\")\n",
    "print(f\"Median Error: €{residuals.median():,.2f}\")\n",
    "print(f\"Std Error: €{residuals.std():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850f163-c51c-426b-939a-d105d98d4301",
   "metadata": {},
   "source": [
    "**Predictions on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50323f3d-ab2c-4b05-9867-12e5b2786efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict salary for new job listings\n",
    "def predict_salary(new_data, model, scaler, feature_cols, is_linear=False):\n",
    "    \"\"\"\n",
    "    Predict salary for new job listings\n",
    "    \n",
    "    Parameters:\n",
    "    new_data: DataFrame with same features as training data\n",
    "    model: trained model\n",
    "    scaler: fitted StandardScaler\n",
    "    feature_cols: list of feature column names\n",
    "    is_linear: whether the model is a linear model (needs scaling)\n",
    "    \"\"\"\n",
    "    # Prepare features\n",
    "    X_new = new_data[feature_cols]\n",
    "    \n",
    "    # Scale if using linear model\n",
    "    if is_linear:\n",
    "        X_new_scaled = scaler.transform(X_new)\n",
    "        predictions = model.predict(X_new_scaled)\n",
    "    else:\n",
    "        predictions = model.predict(X_new)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example: Predict for jobs with different keyword combinations\n",
    "is_linear = 'Regression' in best_model_name and 'Forest' not in best_model_name\n",
    "\n",
    "sample_data = X_test.head(10)\n",
    "sample_predictions = predict_salary(sample_data, best_model, scaler, feature_cols, is_linear)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "results_list = []\n",
    "for i, (idx, row) in enumerate(sample_data.iterrows()):\n",
    "    actual = y_test.loc[idx]\n",
    "    predicted = sample_predictions[i]\n",
    "    error = abs(predicted - actual)\n",
    "    error_pct = (error / actual) * 100\n",
    "    \n",
    "    # Get original job info\n",
    "    job_title = df_clean.loc[idx, 'display_name']\n",
    "    city = df_clean.loc[idx, 'city']\n",
    "    \n",
    "    results_list.append({\n",
    "        'Job': job_title[:50],\n",
    "        'City': city,\n",
    "        'Predicted': f\"€{predicted:,.0f}\",\n",
    "        'Actual': f\"€{actual:,.0f}\",\n",
    "        'Error': f\"€{error:,.0f}\",\n",
    "        'Error %': f\"{error_pct:.1f}%\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42224a0-6e16-4140-b7a6-05f63b9d663b",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d6f1b-6a82-42c2-91a8-8deb909e4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best model, scaler, and all necessary objects\n",
    "model_package = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'feature_cols': feature_cols,\n",
    "    'label_encoders': label_encoders,\n",
    "    'tfidf_vectorizer': tfidf,\n",
    "    'keywords_dict': keywords_dict,\n",
    "    'high_impact_keywords': high_impact_keywords,\n",
    "    'model_name': best_model_name,\n",
    "    'is_linear': is_linear\n",
    "}\n",
    "\n",
    "with open('salary_prediction_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "print(\"Model package saved successfully!\")\n",
    "print(f\"\\nPackage contents:\")\n",
    "for key in model_package.keys():\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "# To load later:\n",
    "# with open('salary_prediction_model.pkl', 'rb') as f:\n",
    "#     saved = pickle.load(f)\n",
    "#     model = saved['model']\n",
    "#     scaler = saved['scaler']\n",
    "#     feature_cols = saved['feature_cols']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
