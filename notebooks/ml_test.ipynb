{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8ad5b0-668c-48db-a839-61662b104c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04137018-7f5b-4ab2-9a72-f461a4103af2",
   "metadata": {},
   "source": [
    "First we load the data by connecting to Postgres and Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a72f4f1-0af4-43d4-9cac-2e205f5bb58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x110abb950>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##connect to postgres db\n",
    "engine = create_engine(os.getenv(\"PG_CONN\"))\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94a9564f-8333-45e1-8e62-4dfccbe63d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>contract_time</th>\n",
       "      <th>created</th>\n",
       "      <th>adref</th>\n",
       "      <th>redirect_url</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>company_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5503199876</td>\n",
       "      <td>Sachbearbeiter Bauunterhaltung (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-19 16:10:49</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...</td>\n",
       "      <td>https://www.adzuna.de/details/5503199876?utm_m...</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5491921252</td>\n",
       "      <td>Fachlagerist (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-12 13:16:58</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...</td>\n",
       "      <td>https://www.adzuna.de/details/5491921252?utm_m...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5496669962</td>\n",
       "      <td>Strategischer Einkäufer (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-14 21:21:25</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5NjY2OTk2MiIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5496669962?utm_m...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5493178189</td>\n",
       "      <td>Metallbauer (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-13 08:47:37</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MzE3ODE4OSIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5493178189?utm_m...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5491386591</td>\n",
       "      <td>Personalreferent (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-12 02:42:57</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MTM4NjU5MSIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5491386591?utm_m...</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                                   title contract_type  \\\n",
       "0  5503199876  Sachbearbeiter Bauunterhaltung (m/w/d)          None   \n",
       "1  5491921252                    Fachlagerist (m/w/d)          None   \n",
       "2  5496669962         Strategischer Einkäufer (m/w/d)          None   \n",
       "3  5493178189                     Metallbauer (m/w/d)          None   \n",
       "4  5491386591                Personalreferent (m/w/d)          None   \n",
       "\n",
       "  contract_time             created  \\\n",
       "0     full_time 2025-11-19 16:10:49   \n",
       "1     full_time 2025-11-12 13:16:58   \n",
       "2     full_time 2025-11-14 21:21:25   \n",
       "3     full_time 2025-11-13 08:47:37   \n",
       "4     full_time 2025-11-12 02:42:57   \n",
       "\n",
       "                                               adref  \\\n",
       "0  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...   \n",
       "1  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...   \n",
       "2  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5NjY2OTk2MiIsI...   \n",
       "3  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MzE3ODE4OSIsI...   \n",
       "4  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MTM4NjU5MSIsI...   \n",
       "\n",
       "                                        redirect_url  salary_min  salary_max  \\\n",
       "0  https://www.adzuna.de/details/5503199876?utm_m...     48000.0     54000.0   \n",
       "1  https://www.adzuna.de/details/5491921252?utm_m...        16.0        18.0   \n",
       "2  https://www.adzuna.de/details/5496669962?utm_m...     70000.0     80000.0   \n",
       "3  https://www.adzuna.de/details/5493178189?utm_m...        18.0        20.0   \n",
       "4  https://www.adzuna.de/details/5491386591?utm_m...     48000.0     54000.0   \n",
       "\n",
       "   company_id  location_id  category_id  \n",
       "0           1            1            1  \n",
       "1           2            2            1  \n",
       "2           3            3            1  \n",
       "3           4            4            1  \n",
       "4           5            5            1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM job\", engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab09f718-09ca-4190-a32d-1a82ca68a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_sql(\"SELECT * FROM job\", engine)\n",
    "com = pd.read_sql(\"SELECT * FROM company\", engine)\n",
    "cat = pd.read_sql(\"SELECT * FROM category\", engine)\n",
    "locs = pd.read_sql(\"SELECT * FROM location\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6280b930-1394-42ed-a2bc-f608f2fdc7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONGO_URI: mongodb://datascientest:dst123@localhost:27017/admin\n"
     ]
    }
   ],
   "source": [
    "# print(\"MONGO_URI:\", os.getenv(\"MONGO_URI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f3bbe17-ca9d-41b9-aac6-c24937c7fc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir: /Users/birgithermsen/Documents/Datascientest/oct25_bde_job_market/notebooks\n",
      ".env exists: False\n"
     ]
    }
   ],
   "source": [
    "# print(\"Current dir:\", os.getcwd())\n",
    "# print(\".env exists:\", os.path.exists(\".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9cf3199-682d-4f2a-b3cd-51c4990a4959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ##connect to mongodb\n",
    "# load_dotenv()\n",
    "\n",
    "# client = MongoClient(\n",
    "#     host=\"127.0.0.1\",\n",
    "#     port=27018,  # Changed port\n",
    "#     username=os.getenv(\"MONGO_USER\"),\n",
    "#     password=os.getenv(\"MONGO_PASS\"),\n",
    "#     authSource=\"admin\",\n",
    "#     serverSelectionTimeoutMS=5000\n",
    "# )\n",
    "\n",
    "# db = client['jobmarketdb']\n",
    "# collection = db['adzunajobs']\n",
    "\n",
    "# cursor = collection.find(\n",
    "#     {},                             # all documents\n",
    "#     {\"_id\": 0, \"job_id\": 1, \"job_description\": 1}   # only these fields\n",
    "# )\n",
    "\n",
    "# df_mongo = pd.DataFrame(list(cursor))\n",
    "# df_mongo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8a58f82-2796-48aa-a354-4a1c60408251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_description</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5494605665</td>\n",
       "      <td>Du weißt, was Du kannst – und suchst einen Arb...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5471852220</td>\n",
       "      <td>DIREKTVERMITTLUNG in Festanstellung (keine Ze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5491386603</td>\n",
       "      <td>Bereit für den nächsten Karriereschritt? Wir b...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5484898587</td>\n",
       "      <td>Du willst Dein Fachwissen in einem neuen Arbei...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5492488590</td>\n",
       "      <td>Unternehmen Ein international tätiges, produzi...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>95000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                                    job_description  salary_min  \\\n",
       "0  5494605665  Du weißt, was Du kannst – und suchst einen Arb...        18.0   \n",
       "1  5471852220   DIREKTVERMITTLUNG in Festanstellung (keine Ze...         NaN   \n",
       "2  5491386603  Bereit für den nächsten Karriereschritt? Wir b...        16.0   \n",
       "3  5484898587  Du willst Dein Fachwissen in einem neuen Arbei...     70000.0   \n",
       "4  5492488590  Unternehmen Ein international tätiges, produzi...     75000.0   \n",
       "\n",
       "   salary_max  \n",
       "0        20.0  \n",
       "1         NaN  \n",
       "2        18.0  \n",
       "3     80000.0  \n",
       "4     95000.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mongo = pd.read_json('adzunajobs.json')\n",
    "df_mongo = df_mongo[['id', 'description', 'salary_min', 'salary_max']]\n",
    "df_mongo = df_mongo.rename(columns={\"id\": \"job_id\", \"description\": \"job_description\"})\n",
    "df_mongo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9ae2013-f2e9-4702-b362-47a8043b97b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>contract_time</th>\n",
       "      <th>created</th>\n",
       "      <th>adref</th>\n",
       "      <th>redirect_url</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>company_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5493178189</td>\n",
       "      <td>Metallbauer (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-13 08:47:37</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MzE3ODE4OSIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5493178189?utm_m...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Emmering, Fürstenfeldbruck (Kreis)</td>\n",
       "      <td>48.180690</td>\n",
       "      <td>11.280780</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Fürstenfeldbruck (Kreis)</td>\n",
       "      <td>Gute Arbeit verdient Anerkennung – und die bek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5491386591</td>\n",
       "      <td>Personalreferent (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-12 02:42:57</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MTM4NjU5MSIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5491386591?utm_m...</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Nordhausen, Nordhausen (Kreis)</td>\n",
       "      <td>51.503530</td>\n",
       "      <td>10.793620</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Nordhausen (Kreis)</td>\n",
       "      <td>Du willst Dein Fachwissen in einem neuen Arbei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5491386575</td>\n",
       "      <td>Fertigungsmitarbeiter Baugruppenmontage (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-12 02:42:50</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...</td>\n",
       "      <td>https://www.adzuna.de/details/5491386575?utm_m...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Innenstadt, Lübeck</td>\n",
       "      <td>53.866240</td>\n",
       "      <td>10.680960</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Lübeck</td>\n",
       "      <td>Dein Talent ist gefragt! Wir suchen engagierte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5480553103</td>\n",
       "      <td>SAP Basis/ BTP Consultant (m/w/d) - 35h/Woche!</td>\n",
       "      <td>permanent</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-04 17:31:44</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4MDU1MzEwMyIsI...</td>\n",
       "      <td>https://www.adzuna.de/details/5480553103?utm_m...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>Bielefeld, Nordrhein-Westfalen</td>\n",
       "      <td>52.021203</td>\n",
       "      <td>8.543293</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Nordrhein-Westfalen</td>\n",
       "      <td>Für ein Technologieunternehmen wird aktuell ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5491607131</td>\n",
       "      <td>CNC-Dreher (m/w/d)</td>\n",
       "      <td>None</td>\n",
       "      <td>full_time</td>\n",
       "      <td>2025-11-12 08:43:34</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...</td>\n",
       "      <td>https://www.adzuna.de/details/5491607131?utm_m...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Zweifall, Stolberg</td>\n",
       "      <td>50.718080</td>\n",
       "      <td>6.257120</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Stolberg</td>\n",
       "      <td>Erfahrung, Einsatz, Ehrgeiz – das ist die Basi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                                            title contract_type  \\\n",
       "0  5493178189                              Metallbauer (m/w/d)          None   \n",
       "1  5491386591                         Personalreferent (m/w/d)          None   \n",
       "2  5491386575  Fertigungsmitarbeiter Baugruppenmontage (m/w/d)          None   \n",
       "3  5480553103   SAP Basis/ BTP Consultant (m/w/d) - 35h/Woche!     permanent   \n",
       "4  5491607131                               CNC-Dreher (m/w/d)          None   \n",
       "\n",
       "  contract_time             created  \\\n",
       "0     full_time 2025-11-13 08:47:37   \n",
       "1     full_time 2025-11-12 02:42:57   \n",
       "2     full_time 2025-11-12 02:42:50   \n",
       "3     full_time 2025-11-04 17:31:44   \n",
       "4     full_time 2025-11-12 08:43:34   \n",
       "\n",
       "                                               adref  \\\n",
       "0  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MzE3ODE4OSIsI...   \n",
       "1  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ5MTM4NjU5MSIsI...   \n",
       "2  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...   \n",
       "3  eyJhbGciOiJIUzI1NiJ9.eyJpIjoiNTQ4MDU1MzEwMyIsI...   \n",
       "4  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiY3FIOXIxREo4QkdIZ...   \n",
       "\n",
       "                                        redirect_url  salary_min  salary_max  \\\n",
       "0  https://www.adzuna.de/details/5493178189?utm_m...        18.0        20.0   \n",
       "1  https://www.adzuna.de/details/5491386591?utm_m...     48000.0     54000.0   \n",
       "2  https://www.adzuna.de/details/5491386575?utm_m...        16.0        18.0   \n",
       "3  https://www.adzuna.de/details/5480553103?utm_m...     70000.0    120000.0   \n",
       "4  https://www.adzuna.de/details/5491607131?utm_m...        20.0        22.0   \n",
       "\n",
       "   company_id  location_id  category_id                        display_name  \\\n",
       "0           4            4            1  Emmering, Fürstenfeldbruck (Kreis)   \n",
       "1           5            5            1      Nordhausen, Nordhausen (Kreis)   \n",
       "2           6            6            1                  Innenstadt, Lübeck   \n",
       "3          10           17            1      Bielefeld, Nordrhein-Westfalen   \n",
       "4          22           22            1                  Zweifall, Stolberg   \n",
       "\n",
       "    latitude  longitude      country                      city  \\\n",
       "0  48.180690  11.280780  Deutschland  Fürstenfeldbruck (Kreis)   \n",
       "1  51.503530  10.793620  Deutschland        Nordhausen (Kreis)   \n",
       "2  53.866240  10.680960  Deutschland                    Lübeck   \n",
       "3  52.021203   8.543293  Deutschland       Nordrhein-Westfalen   \n",
       "4  50.718080   6.257120  Deutschland                  Stolberg   \n",
       "\n",
       "                                     job_description  \n",
       "0  Gute Arbeit verdient Anerkennung – und die bek...  \n",
       "1  Du willst Dein Fachwissen in einem neuen Arbei...  \n",
       "2  Dein Talent ist gefragt! Wir suchen engagierte...  \n",
       "3  Für ein Technologieunternehmen wird aktuell ei...  \n",
       "4  Erfahrung, Einsatz, Ehrgeiz – das ist die Basi...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##combine data into one df\n",
    "df = jobs.merge(locs)\n",
    "df = df.merge(df_mongo)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0c37f94-a09a-4a51-a657-8a930b7481ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "job_id                      int64\n",
      "title                      object\n",
      "contract_type              object\n",
      "contract_time              object\n",
      "created            datetime64[ns]\n",
      "adref                      object\n",
      "redirect_url               object\n",
      "salary_min                float64\n",
      "salary_max                float64\n",
      "company_id                  int64\n",
      "location_id                 int64\n",
      "category_id                 int64\n",
      "display_name               object\n",
      "latitude                  float64\n",
      "longitude                 float64\n",
      "country                    object\n",
      "city                       object\n",
      "job_description            object\n",
      "dtype: object\n",
      "\n",
      "==================================================\n",
      "\n",
      "Missing Values:\n",
      "               Missing_Count  Percentage\n",
      "contract_type             17   60.714286\n",
      "salary_min                 5   17.857143\n",
      "salary_max                 5   17.857143\n",
      "contract_time              2    7.142857\n",
      "latitude                   1    3.571429\n",
      "longitude                  1    3.571429\n",
      "city                       1    3.571429\n",
      "\n",
      "==================================================\n",
      "\n",
      "Basic Statistics:\n",
      "             job_id                        created     salary_min  \\\n",
      "count  2.800000e+01                             28      23.000000   \n",
      "mean   5.489646e+09  2025-11-10 20:02:30.321428224   35139.652174   \n",
      "min    5.474060e+09            2025-11-01 06:05:51      16.000000   \n",
      "25%    5.488913e+09  2025-11-10 04:46:26.249999872      18.000000   \n",
      "50%    5.491497e+09     2025-11-12 05:43:21.500000   40000.000000   \n",
      "75%    5.492839e+09            2025-11-13 00:13:52   70000.000000   \n",
      "max    5.498587e+09            2025-11-16 01:35:24  105000.000000   \n",
      "std    6.007628e+06                            NaN   36744.644422   \n",
      "\n",
      "          salary_max  company_id  location_id  category_id   latitude  \\\n",
      "count      23.000000   28.000000    28.000000         28.0  27.000000   \n",
      "mean    73662.347826   33.428571    48.464286          1.0  51.073405   \n",
      "min        18.000000    4.000000     4.000000          1.0  48.040860   \n",
      "25%        20.000000   10.000000    20.750000          1.0  50.283396   \n",
      "50%     45000.000000   16.000000    47.000000          1.0  51.053290   \n",
      "75%     95000.000000   51.000000    73.250000          1.0  52.496018   \n",
      "max    800000.000000  110.000000   110.000000          1.0  53.866240   \n",
      "std    164270.391139   34.166725    34.294457          0.0   1.750050   \n",
      "\n",
      "       longitude  \n",
      "count  27.000000  \n",
      "mean   10.248929  \n",
      "min     6.257120  \n",
      "25%     8.654219  \n",
      "50%    10.325230  \n",
      "75%    12.517910  \n",
      "max    13.937400  \n",
      "std     2.348075  \n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing_Count'] > 0].sort_values('Percentage', ascending=False))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14d675-1be4-4495-bb76-b3b7550eccff",
   "metadata": {},
   "source": [
    "**Data Prep and Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "184a4a53-b30f-4b8b-84bc-c498b93dbd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "\n",
      "Rows after cleaning: 12 (removed 16 rows)\n",
      "Missing values remaining:\n",
      "contract_type    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Handle missing values in numeric columns (latitude, longitude)\n",
    "print(\"Handling missing values...\")\n",
    "\n",
    "# df_clean = df_clean.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# 2. Handle missing values in categorical columns (city, country)\n",
    "# Fill with 'Unknown' or mode\n",
    "df_clean['city'].fillna('Unknown', inplace=True)\n",
    "df_clean['country'].fillna('Deutschland', inplace=True)  \n",
    "\n",
    "# 3. Handle salary columns - remove rows where salary is missing or invalid\n",
    "df_clean = df_clean.dropna(subset=['salary_min', 'salary_max'])\n",
    "\n",
    "# Remove rows where salary_max < salary_min (data quality issue)\n",
    "df_clean = df_clean[df_clean['salary_max'] >= df_clean['salary_min']]\n",
    "\n",
    "# Remove hourly salaries\n",
    "df_clean = df_clean[df_clean['salary_min'] > 100]\n",
    "\n",
    "\n",
    "print(f\"\\nRows after cleaning: {len(df_clean)} (removed {len(df) - len(df_clean)} rows)\")\n",
    "print(f\"Missing values remaining:\\n{df_clean.isnull().sum()[df_clean.isnull().sum() > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a7b332c-96c8-472b-97fd-588aa0781ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Du willst Dein Fachwissen in einem neuen Arbei...\n",
       "3     Für ein Technologieunternehmen wird aktuell ei...\n",
       "7     Du willst Dein Fachwissen in einem neuen Arbei...\n",
       "8     Unser Auftraggeber, ein zukunftsorientiertes F...\n",
       "9     Für unseren Kunden, ein international führende...\n",
       "11    Ein innovatives Unternehmen aus der Konsumgüte...\n",
       "12    Unser Auftraggeber, ein zukunftsorientiertes U...\n",
       "13    Du willst Dein Fachwissen in einem neuen Arbei...\n",
       "15    Derzeit wird ein SAP SD Inhouse Consultant (m/...\n",
       "17    Unternehmen Ein international tätiges, produzi...\n",
       "21    Du willst Dein Fachwissen in einem neuen Arbei...\n",
       "24    Bei unserem Auftraggeber wird eine erfahrene P...\n",
       "Name: job_description, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['job_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15149855-7904-42fc-8358-f763d63d0ec2",
   "metadata": {},
   "source": [
    "**Keyword extraction from job description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbbe4e66-1ca9-41ec-bf4e-86dc4e0c2124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seniority: mean count = 0.42\n",
      "languages: mean count = 1.08\n",
      "frameworks: mean count = 0.00\n",
      "databases: mean count = 0.00\n",
      "cloud: mean count = 0.08\n",
      "data_ai: mean count = 0.00\n",
      "methodologies: mean count = 0.00\n",
      "management: mean count = 0.42\n",
      "education: mean count = 0.08\n",
      "experience: mean count = 0.08\n",
      "domains: mean count = 0.42\n",
      "company_type: mean count = 0.00\n",
      "benefits: mean count = 0.17\n",
      "\n",
      "Created 13 category count features\n",
      "Created 16 binary keyword features\n"
     ]
    }
   ],
   "source": [
    "# Fill missing descriptions\n",
    "df_clean['job_description'] = df_clean['job_description'].fillna('')\n",
    "\n",
    "# Convert to lowercase for consistency\n",
    "df_clean['desc_lower'] = df_clean['job_description'].str.lower()\n",
    "\n",
    "# Define comprehensive keyword categories\n",
    "keywords_dict = {\n",
    "    # Seniority levels\n",
    "    'seniority': ['senior', 'lead', 'principal', 'staff', 'junior', 'entry', \n",
    "                  'experienced', 'expert', 'chief', 'head of', 'director', 'vp',\n",
    "                  'leitend', 'erfahren', 'anfänger', 'einsteiger', 'fachlich', 'leiter', 'direktor'],\n",
    "    \n",
    "    # Technical skills - Programming languages\n",
    "    'languages': ['python', 'java', 'javascript', 'typescript', 'c++', 'c#', \n",
    "                  'ruby', 'go', 'rust', 'scala', 'kotlin', 'swift', 'php', 'r'],\n",
    "    \n",
    "    # Frameworks & Technologies\n",
    "    'frameworks': ['react', 'angular', 'vue', 'django', 'flask', 'spring', \n",
    "                   'node.js', 'express', '.net', 'tensorflow', 'pytorch', 'keras'],\n",
    "    \n",
    "    # Databases\n",
    "    'databases': ['sql', 'mysql', 'postgresql', 'mongodb', 'oracle', 'redis', \n",
    "                  'elasticsearch', 'cassandra', 'dynamodb', 'neo4j'],\n",
    "    \n",
    "    # Cloud & DevOps\n",
    "    'cloud': ['aws', 'azure', 'gcp', 'cloud', 'docker', 'kubernetes', 'k8s',\n",
    "              'terraform', 'ansible', 'jenkins', 'gitlab', 'ci/cd', 'devops'],\n",
    "    \n",
    "    # Data & AI\n",
    "    'data_ai': ['machine learning', 'deep learning', 'ai', 'data science', \n",
    "                'analytics', 'big data', 'etl', 'data warehouse', 'spark', \n",
    "                'hadoop', 'tableau', 'power bi', 'künstliche intelligenz',\n",
    "                'datenwissenschaft', 'datenanalyse', 'datenlager'],\n",
    "    \n",
    "    # Methodologies\n",
    "    'methodologies': ['agile', 'scrum', 'kanban', 'waterfall', 'test-driven',\n",
    "                      'microservices', 'rest', 'api', 'graphql'],\n",
    "    \n",
    "    # Soft skills & Management\n",
    "    'management': ['team lead', 'leadership', 'management', 'communication',\n",
    "                   'project management', 'stakeholder', 'mentor', 'architect',\n",
    "                   'teamleitung', 'führung', 'kommunikation', 'projektleitung', 'mentor', 'architekt'],\n",
    "    \n",
    "    # Education requirements\n",
    "    'education': ['bachelor', 'master', 'phd', 'doctorate', 'degree', \n",
    "                  'university', 'certification', 'certified',\n",
    "                  'bachelorabschluss', 'masterabschluss', 'doktor', 'abschluss', 'universität', 'zertifizierung', 'zertifiziert'],\n",
    "    \n",
    "    # Experience indicators\n",
    "    'experience': ['years of experience', 'year experience', 'experience in',\n",
    "                   'proven track record', 'extensive experience', 'jahre erfahrung', 'erfahrung in', \n",
    "                   'nachweisliche erfahrung', 'umfangreiche erfahrung'],\n",
    "    \n",
    "    # Domain expertise\n",
    "    'domains': ['finance', 'fintech', 'healthcare', 'e-commerce', 'automotive',\n",
    "                'telecommunications', 'gaming', 'security', 'blockchain', 'iot',\n",
    "                'finanzen', 'gesundheitswesen', 'handel', 'automobil', 'telekommunikation',\n",
    "                'sicherheit', 'internet der dinge'],\n",
    "    \n",
    "    # Company size indicators\n",
    "    'company_type': ['startup', 'enterprise', 'corporation', 'sme', 'scale-up',\n",
    "                     'fortune 500', 'multinational'],\n",
    "    \n",
    "    # Benefits (often correlate with higher salaries)\n",
    "    'benefits': ['remote', 'flexible', 'home office', 'relocation', 'visa',\n",
    "                 'bonus', 'stock options', 'equity', '30 days vacation',\n",
    "                 'flexibel', 'heimarbeit', 'umzug', 'urlaub', 'aktienoptionen']\n",
    "}\n",
    "\n",
    "# Count keyword occurrences in each category\n",
    "for category, keywords in keywords_dict.items():\n",
    "    df_clean[f'{category}_count'] = 0\n",
    "    for keyword in keywords:\n",
    "        df_clean[f'{category}_count'] += df_clean['desc_lower'].str.contains(\n",
    "            keyword, regex=False, na=False\n",
    "        ).astype(int)\n",
    "    print(f\"{category}: mean count = {df_clean[f'{category}_count'].mean():.2f}\")\n",
    "\n",
    "# Create binary features for high-impact individual keywords\n",
    "high_impact_keywords = [\n",
    "    'senior', 'lead', 'principal', 'architect', 'expert',\n",
    "    'python', 'java', 'aws', 'azure', 'kubernetes',\n",
    "    'machine learning', 'ai', 'blockchain', \n",
    "    'remote', 'phd', 'team lead'\n",
    "]\n",
    "\n",
    "for keyword in high_impact_keywords:\n",
    "    col_name = f\"has_{keyword.replace(' ', '_')}\"\n",
    "    df_clean[col_name] = df_clean['desc_lower'].str.contains(\n",
    "        keyword, regex=False, na=False\n",
    "    ).astype(int)\n",
    "\n",
    "print(f\"\\nCreated {len(keywords_dict)} category count features\")\n",
    "print(f\"Created {len(high_impact_keywords)} binary keyword features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41dbd3-cb81-4282-8a84-69a7713ee734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional text-based features\n",
    "# df_clean['desc_length'] = df_clean['job_description'].str.len()\n",
    "# df_clean['desc_word_count'] = df_clean['job_description'].str.split().str.len()\n",
    "# df_clean['desc_sentence_count'] = df_clean['job_description'].str.count(r'[.!?]+')\n",
    "\n",
    "# # Extract years of experience mentioned (e.g., \"5+ years\", \"3-5 years\")\n",
    "# import re\n",
    "\n",
    "# def extract_years_experience(text):\n",
    "#     if pd.isna(text) or text == '':\n",
    "#         return 0\n",
    "#     # Look for patterns like \"5+ years\", \"3-5 years\", \"5 years\"\n",
    "#     patterns = [\n",
    "#         r'(\\d+)\\+?\\s*(?:years?|jahr)',  # 5+ years, 5 years\n",
    "#         r'(\\d+)\\s*(?:-|to|bis)\\s*\\d+\\s*(?:years?|jahr)',  # 3-5 years\n",
    "#     ]\n",
    "#     years = []\n",
    "#     for pattern in patterns:\n",
    "#         matches = re.findall(pattern, text.lower())\n",
    "#         years.extend([int(m) for m in matches if m])\n",
    "#     return max(years) if years else 0\n",
    "\n",
    "# df_clean['years_experience_required'] = df_clean['job_description'].apply(extract_years_experience)\n",
    "\n",
    "# # Count technical requirements\n",
    "# df_clean['requirements_count'] = df_clean['desc_lower'].str.count(\n",
    "#     r'\\b(require|must|need|essential|mandatory)\\b'\n",
    "# )\n",
    "\n",
    "# # Count \"nice to have\" vs \"must have\"\n",
    "# df_clean['nice_to_have_count'] = df_clean['desc_lower'].str.count(\n",
    "#     r'\\b(nice to have|preferred|bonus|plus|advantage)\\b'\n",
    "# )\n",
    "\n",
    "# print(\"Advanced text features:\")\n",
    "# print(df_clean[['desc_length', 'desc_word_count', 'years_experience_required', \n",
    "#                 'requirements_count', 'nice_to_have_count']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c72a4275-2592-45d9-b52f-17311b96ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK not available, using custom stopwords\n",
      "\n",
      "Top 20 TF-IDF terms found in German job descriptions:\n",
      "  1. aufgaben\n",
      "  2. fokus\n",
      "  3. implementierung\n",
      "  4. kunden\n",
      "  5. sap\n",
      "\n",
      "Added 5 TF-IDF features\n",
      "\n",
      "Top 10 salary-correlated German terms:\n",
      "  kunden: -0.427 (lower salary)\n",
      "  aufgaben: -0.344 (lower salary)\n",
      "  sap: 0.216 (higher salary)\n",
      "  implementierung: 0.054 (higher salary)\n",
      "  fokus: 0.027 (higher salary)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Option 1: Use a German stopwords list (recommended)\n",
    "# Install: pip install nltk\n",
    "try:\n",
    "    import nltk\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    from nltk.corpus import stopwords\n",
    "    german_stop_words = stopwords.words('german')\n",
    "    print(f\"Using NLTK German stopwords: {len(german_stop_words)} words\")\n",
    "except:\n",
    "    print(\"NLTK not available, using custom stopwords\")\n",
    "    # Option 2: Manual German stopwords list\n",
    "    # Note: Use base forms without umlauts if using strip_accents\n",
    "    german_stop_words = [\n",
    "        'der', 'die', 'und', 'in', 'den', 'von', 'zu', 'das', 'mit', 'sich',\n",
    "        'des', 'auf', 'fur', 'ist', 'im', 'dem', 'nicht', 'ein', 'eine',\n",
    "        'als', 'auch', 'es', 'an', 'werden', 'aus', 'er', 'hat', 'dass',\n",
    "        'sie', 'nach', 'wird', 'bei', 'einer', 'um', 'am', 'sind', 'noch',\n",
    "        'wie', 'einem', 'uber', 'einen', 'so', 'zum', 'war', 'haben', 'nur',\n",
    "        'oder', 'aber', 'vor', 'zur', 'bis', 'mehr', 'durch', 'man', 'sein',\n",
    "        'wurde', 'sei', 'wir', 'ihre', 'bzw', 'sowie', 'inkl', \n",
    "        'ggf', 'etc', 'ca', 'innen', 'unser', 'unseren', 'unternehmen', 'suchen'\n",
    "    ]\n",
    "\n",
    "# Create TF-IDF features from job descriptions\n",
    "# Use a limited number of features to avoid overfitting\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50,  # Top 50 most important terms\n",
    "    min_df=5,  # Term must appear in at least 5 documents\n",
    "    max_df=0.8,  # Ignore terms that appear in more than 80% of documents\n",
    "    ngram_range=(1, 2),  # Use single words and bi-grams\n",
    "    stop_words=german_stop_words,  # Remove common German words\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode'  # Handle umlauts better\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "tfidf_features = tfidf.fit_transform(df_clean['job_description'].fillna(''))\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_features.toarray(),\n",
    "    columns=[f'tfidf_{i}' for i in range(tfidf_features.shape[1])],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "# Show most important terms\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(\"\\nTop 20 TF-IDF terms found in German job descriptions:\")\n",
    "for i, term in enumerate(feature_names[:20]):\n",
    "    print(f\"  {i+1}. {term}\")\n",
    "\n",
    "# Merge TF-IDF features with main dataframe\n",
    "df_clean = pd.concat([df_clean, tfidf_df], axis=1)\n",
    "\n",
    "print(f\"\\nAdded {tfidf_features.shape[1]} TF-IDF features\")\n",
    "\n",
    "# Optional: Show which terms are most correlated with salary\n",
    "if 'salary_avg' in df_clean.columns:\n",
    "    correlations = []\n",
    "    for col in tfidf_df.columns:\n",
    "        # Fix: Use correct correlation calculation between two Series\n",
    "        corr = df_clean[[col, 'salary_avg']].corr().iloc[0, 1]\n",
    "        if not pd.isna(corr):\n",
    "            idx = int(col.split('_')[1])\n",
    "            correlations.append((col, corr, feature_names[idx]))\n",
    "    \n",
    "    correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    print(\"\\nTop 10 salary-correlated German terms:\")\n",
    "    for col, corr, term in correlations[:10]:\n",
    "        direction = \"higher\" if corr > 0 else \"lower\"\n",
    "        print(f\"  {term}: {corr:.3f} ({direction} salary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a9cd1-25d7-407b-b6ea-8f098fe7726e",
   "metadata": {},
   "source": [
    "**Feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec9142b6-bf63-4698-b82a-96ec43849e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete!\n",
      "Total features: 146\n",
      "\n",
      "Top 15 text features correlated with salary:\n",
      "seniority_count     0.454776\n",
      "tfidf_16            0.331544\n",
      "domains_count       0.249320\n",
      "cloud_count        -0.026214\n",
      "languages_count    -0.026214\n",
      "experience_count   -0.061638\n",
      "benefits_count     -0.061638\n",
      "has_remote         -0.061638\n",
      "has_expert         -0.065153\n",
      "education_count    -0.111232\n",
      "tfidf_23           -0.148829\n",
      "management_count   -0.168803\n",
      "title_word_count   -0.231713\n",
      "tfidf_22           -0.295348\n",
      "tfidf_13           -0.321347\n",
      "Name: salary_avg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create target variable: average salary\n",
    "df_clean['salary_avg'] = (df_clean['salary_min'] + df_clean['salary_max']) / 2\n",
    "df_clean['salary_range'] = df_clean['salary_max'] - df_clean['salary_min']\n",
    "\n",
    "# Create binary features from categorical variables\n",
    "df_clean['has_location'] = df_clean['city'].notna().astype(int)\n",
    "\n",
    "# Extract useful features from display_name (job title)\n",
    "df_clean['title_length'] = df_clean['display_name'].str.len()\n",
    "df_clean['title_word_count'] = df_clean['display_name'].str.split().str.len()\n",
    "\n",
    "# Check for keywords in job titles\n",
    "title_keywords = ['senior', 'lead', 'manager', 'engineer', 'developer']\n",
    "for keyword in title_keywords:\n",
    "    df_clean[f'title_is_{keyword}'] = df_clean['display_name'].str.lower().str.contains(\n",
    "        keyword, na=False\n",
    "    ).astype(int)\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(f\"Total features: {len(df_clean.columns)}\")\n",
    "\n",
    "# Show correlation of text features with salary\n",
    "# Only include numeric feature columns, not the raw text columns\n",
    "text_feature_cols = [col for col in df_clean.columns if any(\n",
    "    x in col for x in ['_count', 'has_', 'years_experience', 'requirements_count', \n",
    "                       'nice_to_have_count', 'tfidf_']\n",
    ") and col not in ['job_description', 'desc_lower', 'display_name']]\n",
    "\n",
    "# Also exclude any non-numeric columns\n",
    "import numpy as np\n",
    "text_feature_cols = [col for col in text_feature_cols \n",
    "                     if pd.api.types.is_numeric_dtype(df_clean[col])]\n",
    "\n",
    "if 'salary_avg' in df_clean.columns and text_feature_cols:\n",
    "    correlations = df_clean[text_feature_cols + ['salary_avg']].corr()['salary_avg'].sort_values(ascending=False)\n",
    "    print(\"\\nTop 15 text features correlated with salary:\")\n",
    "    print(correlations[1:16])  # Skip salary_avg itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a534ba3b-9cea-48da-9f40-9ea9548a960c",
   "metadata": {},
   "source": [
    "**Encode categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e37ba8e1-94f3-4cec-9833-0a7d366ede6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_clean.columns:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m         le = \u001b[43mLabelEncoder\u001b[49m()\n\u001b[32m     18\u001b[39m         df_clean[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_encoded\u001b[39m\u001b[33m'\u001b[39m] = le.fit_transform(df_clean[col].astype(\u001b[38;5;28mstr\u001b[39m))\n\u001b[32m     19\u001b[39m         label_encoders[col] = le\n",
      "\u001b[31mNameError\u001b[39m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Select features for modeling\n",
    "categorical_cols = ['country', 'city']\n",
    "\n",
    "# Get all text-based features we created\n",
    "text_feature_cols = [col for col in df_clean.columns if any(\n",
    "    x in col for x in ['_count', 'has_', 'desc_length', 'desc_word_count', \n",
    "                       'years_experience', 'requirements_count', 'nice_to_have_count',\n",
    "                       'title_is_', 'tfidf_']\n",
    ")]\n",
    "\n",
    "numeric_cols = ['latitude', 'longitude', 'title_length', 'title_word_count'] + text_feature_cols\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_clean[f'{col}_encoded'] = le.fit_transform(df_clean[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Frequency encoding for city (better for high cardinality)\n",
    "city_freq = df_clean['city'].value_counts(normalize=True)\n",
    "df_clean['city_frequency'] = df_clean['city'].map(city_freq)\n",
    "\n",
    "print(f\"Total numeric/text features: {len(text_feature_cols)}\")\n",
    "print(\"Encoded features complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eabbc5-4c35-4327-bc2c-ef06d1cb6c99",
   "metadata": {},
   "source": [
    "**Prepare for data modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a87dc24d-0045-43c2-9586-5f7be70e3486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete!\n",
      "Total features: 146\n",
      "\n",
      "Top 15 text features correlated with salary:\n",
      "seniority_count     0.454776\n",
      "tfidf_16            0.331544\n",
      "domains_count       0.249320\n",
      "cloud_count        -0.026214\n",
      "languages_count    -0.026214\n",
      "experience_count   -0.061638\n",
      "benefits_count     -0.061638\n",
      "has_remote         -0.061638\n",
      "has_expert         -0.065153\n",
      "education_count    -0.111232\n",
      "tfidf_23           -0.148829\n",
      "management_count   -0.168803\n",
      "title_word_count   -0.231713\n",
      "tfidf_22           -0.295348\n",
      "tfidf_13           -0.321347\n",
      "Name: salary_avg, dtype: float64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17434dfd-b950-4e74-8af2-b8243c327395",
   "metadata": {},
   "source": [
    "**Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a772e03-3db4-4ea8-a6de-b05750e2361e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Split into train and test sets\u001b[39;00m\n\u001b[32m      2\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mX\u001b[49m, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures scaled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec67755-a115-4674-b441-dbdc9428670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb  # Install with: pip install xgboost\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=200, \n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled data for linear models, original for tree-based\n",
    "    if 'Regression' in name and 'Forest' not in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"  MAE: €{mae:,.2f}\")\n",
    "    print(f\"  RMSE: €{rmse:,.2f}\")\n",
    "    print(f\"  R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc947da-5897-4120-bfd7-06807a615f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model (highest R2)\n",
    "best_model_name = comparison_df.loc[comparison_df['R2'].idxmax(), 'Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# Feature importance for tree-based models\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features:\")\n",
    "    print(importance_df.head(20).to_string(index=False))\n",
    "    \n",
    "    # Categorize features\n",
    "    text_features = importance_df[importance_df['Feature'].str.contains('has_|_count|tfidf_|years_experience')]\n",
    "    location_features = importance_df[importance_df['Feature'].str.contains('city|country|latitude|longitude')]\n",
    "    \n",
    "    print(f\"\\nTop text-based features:\")\n",
    "    print(text_features.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize top features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(20)\n",
    "    plt.barh(top_features['Feature'], top_features['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show keyword category importance\n",
    "    category_importance = {}\n",
    "    for category in keywords_dict.keys():\n",
    "        cat_features = importance_df[importance_df['Feature'].str.contains(category)]\n",
    "        if len(cat_features) > 0:\n",
    "            category_importance[category] = cat_features['Importance'].sum()\n",
    "    \n",
    "    if category_importance:\n",
    "        cat_imp_df = pd.DataFrame(list(category_importance.items()), \n",
    "                                   columns=['Category', 'Total_Importance']).sort_values('Total_Importance', ascending=False)\n",
    "        print(\"\\nKeyword category importance:\")\n",
    "        print(cat_imp_df.to_string(index=False))\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(cat_imp_df['Category'], cat_imp_df['Total_Importance'])\n",
    "        plt.xlabel('Total Importance')\n",
    "        plt.title('Keyword Category Importance')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# For linear models, show coefficients\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Coefficient': best_model.coef_\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features (by coefficient magnitude):\")\n",
    "    print(coef_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27a416-ab49-45fe-a30f-e8c92e1d0802",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3944ac5-b749-48d3-b3e8-b63d3445c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize predictions vs actual\n",
    "# best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# # Scatter plot\n",
    "# axes[0].scatter(y_test, best_predictions, alpha=0.5)\n",
    "# axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "# axes[0].set_xlabel('Actual Salary (€)')\n",
    "# axes[0].set_ylabel('Predicted Salary (€)')\n",
    "# axes[0].set_title(f'Actual vs Predicted Salaries - {best_model_name}')\n",
    "\n",
    "# # Residual plot\n",
    "# residuals = y_test - best_predictions\n",
    "# axes[1].scatter(best_predictions, residuals, alpha=0.5)\n",
    "# axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "# axes[1].set_xlabel('Predicted Salary (€)')\n",
    "# axes[1].set_ylabel('Residuals (€)')\n",
    "# axes[1].set_title('Residual Plot')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Distribution of errors\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(residuals, bins=50, edgecolor='black')\n",
    "# plt.xlabel('Prediction Error (€)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Prediction Errors')\n",
    "# plt.axvline(x=0, color='r', linestyle='--', label='Perfect Prediction')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"\\nError Statistics:\")\n",
    "# print(f\"Mean Error: €{residuals.mean():,.2f}\")\n",
    "# print(f\"Median Error: €{residuals.median():,.2f}\")\n",
    "# print(f\"Std Error: €{residuals.std():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850f163-c51c-426b-939a-d105d98d4301",
   "metadata": {},
   "source": [
    "**Predictions on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50323f3d-ab2c-4b05-9867-12e5b2786efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict salary for new job listings\n",
    "def predict_salary(new_data, model, scaler, feature_cols, is_linear=False):\n",
    "    \"\"\"\n",
    "    Predict salary for new job listings\n",
    "    \n",
    "    Parameters:\n",
    "    new_data: DataFrame with same features as training data\n",
    "    model: trained model\n",
    "    scaler: fitted StandardScaler\n",
    "    feature_cols: list of feature column names\n",
    "    is_linear: whether the model is a linear model (needs scaling)\n",
    "    \"\"\"\n",
    "    # Prepare features\n",
    "    X_new = new_data[feature_cols]\n",
    "    \n",
    "    # Scale if using linear model\n",
    "    if is_linear:\n",
    "        X_new_scaled = scaler.transform(X_new)\n",
    "        predictions = model.predict(X_new_scaled)\n",
    "    else:\n",
    "        predictions = model.predict(X_new)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example: Predict for jobs with different keyword combinations\n",
    "is_linear = 'Regression' in best_model_name and 'Forest' not in best_model_name\n",
    "\n",
    "sample_data = X_test.head(10)\n",
    "sample_predictions = predict_salary(sample_data, best_model, scaler, feature_cols, is_linear)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "results_list = []\n",
    "for i, (idx, row) in enumerate(sample_data.iterrows()):\n",
    "    actual = y_test.loc[idx]\n",
    "    predicted = sample_predictions[i]\n",
    "    error = abs(predicted - actual)\n",
    "    error_pct = (error / actual) * 100\n",
    "    \n",
    "    # Get original job info\n",
    "    job_title = df_clean.loc[idx, 'display_name']\n",
    "    city = df_clean.loc[idx, 'city']\n",
    "    \n",
    "    results_list.append({\n",
    "        'Job': job_title[:50],\n",
    "        'City': city,\n",
    "        'Predicted': f\"€{predicted:,.0f}\",\n",
    "        'Actual': f\"€{actual:,.0f}\",\n",
    "        'Error': f\"€{error:,.0f}\",\n",
    "        'Error %': f\"{error_pct:.1f}%\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42224a0-6e16-4140-b7a6-05f63b9d663b",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d6f1b-6a82-42c2-91a8-8deb909e4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best model, scaler, and all necessary objects\n",
    "model_package = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'feature_cols': feature_cols,\n",
    "    'label_encoders': label_encoders,\n",
    "    'tfidf_vectorizer': tfidf,\n",
    "    'keywords_dict': keywords_dict,\n",
    "    'high_impact_keywords': high_impact_keywords,\n",
    "    'model_name': best_model_name,\n",
    "    'is_linear': is_linear\n",
    "}\n",
    "\n",
    "with open('salary_prediction_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "print(\"Model package saved successfully!\")\n",
    "print(f\"\\nPackage contents:\")\n",
    "for key in model_package.keys():\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "# To load later:\n",
    "# with open('salary_prediction_model.pkl', 'rb') as f:\n",
    "#     saved = pickle.load(f)\n",
    "#     model = saved['model']\n",
    "#     scaler = saved['scaler']\n",
    "#     feature_cols = saved['feature_cols']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
